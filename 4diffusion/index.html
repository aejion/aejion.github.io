<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Multi-view Video Diffusion Model for 4D Generation">
  <meta name="keywords" content="4D Generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>4Diffusion: Multi-view Video Diffusion Model for 4D Generation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!--say sth-->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">4Diffusion: Multi-view Video Diffusion Model for 4D Generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
            <a href="https://github.com/aejion">Haiyu Zhang</a><sup>1,2</sup>,</span>
              <span class="author-block">
              <a href="https://scholar.google.com/citations?user=3fWSC8YAAAAJ">Xinyuan Chen</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://wyhsirius.github.io/">Yaohui Wang</a><sup>2</sup>,</span>
                <span class="author-block">
              <a href="https://xh-liu.github.io/">Xihui Liu</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://irip.buaa.edu.cn/yhwang/index.html">Yunhong Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <span class="author-block">
                <a href="https://scholar.google.com.hk/citations?user=gFtI-8QAAAAJ&hl=zh-CN">Yu Qiao</a><sup>2†</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Beihang University, </span>
            <span class="author-block"><sup>2</sup>Shanghai AI Laboratory, </span>
            <span class="author-block"><sup>3</sup>The University of Hong Kong </span>
          </div>

          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>†</sup>Corresponding author</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. TODO -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>    
              <!-- Code Link.  TODO-->
              <span class="link-block">
                <a href="https://github.com/aejion/4Diffusion"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
      <h2 class="subtitle has-text-centered">
        <b>TL;DR:</b> We present a novel 4D generation pipeline that generates high-quality spatial-temporal consistent 4D content from a monocular video with a multi-view video diffusion model.
      </h2>
  </div>
</section>


<section class="section">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-three-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Current 4D generation methods have achieved noteworthy efficacy with the aid of advanced diffusion generative models. However, these methods lack multi-view spatial-temporal modeling and encounter challenges in integrating diverse prior knowledge from multiple diffusion models, 
            resulting in inconsistent temporal appearance and flickers. In this paper, we propose a novel 4D generation pipeline, namely <b>4Diffusion</b>, aimed at generating spatial-temporally consistent 4D content from a monocular video. We first design a unified diffusion model tailored for multi-view 
            video generation by incorporating a learnable motion module into a frozen 3D-aware diffusion model to capture multi-view spatial-temporal correlations. After training on a curated dataset, 
            our diffusion model acquires reasonable temporal consistency and inherently preserves the generalizability and spatial consistency of the 3D-aware diffusion model. Subsequently, we propose 4D-aware Score Distillation Sampling loss, which is based on our multi-view video diffusion model, to optimize
             4D representation parameterized by dynamic NeRF. This aims to eliminate discrepancies arising 
             from multiple diffusion models, allowing for generating spatial-temporally consistent 4D content. Moreover, 
             we devise an anchor loss to enhance the appearance details and facilitate the learning of dynamic NeRF.
              Extensive qualitative and quantitative experiments demonstrate that our method achieves superior performance compared to previous methods.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
     <!-- Method. -->
     <div class="columns is-centered has-text-centered">
      <div class="column is-three-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <p>
            Our method first trains a unified diffusion, named 4DM, by inserting a learnable motion module 
            at the end of each frozen spatial module of ImageDream to capture multi-view spatial-temporal 
            correlations. Given a monocular video and text prompt, 4DM can produce consistent multi-view videos. 
            Then, we combine 4D-aware SDS and an anchor loss based on 4DM to optimize 4D representation 
            parameterized by Dynamic NeRF.
          </p>
          <img src="./static/images/pipeline.png">
        </div>
      </div>
    </div>
    <!--/ Method. -->
    <!-- Video-to-4D. -->
    <div class="container is-max-desktop">

      <div class="columns is-centered">
  

  
        <!-- Visual Effects. -->
        <div class="column">
          <div class="content">
            <h2 class="title is-3">Video-to-4D Generation</h2>
            <p>
              We compare 4Diffusion to 4D-fy, Consistent4D, and DreamGaussian4D on monocular video-to-4D task.
            4Diffusion generates high-quality 4D content with our multi-view video diffusion model 4DM.
            </p>
            <!--<img src="./static/images/exhibit_mode23.jpg" alt="Video-to-4D">-->
          </div>
        </div>
        <!--/ Visual Effects. -->
  
        
        </div>
      </div>
    <!--/ Video-to-4D. -->
    <div class="container is-max-desktop">
      
      <div class="columns is-centered">
  
        <!-- Visual Effects. -->
        <div class="column">
          <video id="messi" autoplay controls muted loop playsinline>
              <source src="./static/videos/video_to_4d.mp4"
                      type="video/mp4">
          </video>
        </div>
        <!--/ Visual Effects. -->
  
      </div>
    </div>

    <!-- Multi-view-video. -->
    <div class="container is-max-desktop">

      <div class="columns is-centered">

        <!-- Visual Effects. -->
        <div class="column">
          <div class="content">
            <h2 class="title is-3">Multi-view Video Generation</h2>
            <p>
              Our multi-view video diffusion model 4DM captures multi-view spatial-temporal correlations, 
              facilitating the generation of multi-view videos.
            </p>
            <!--<img src="./static/images/exhibit_mode23.jpg" alt="Video-to-4D">-->
          </div>
        </div>
        <!--/ Visual Effects. -->
  
        
        </div>
      </div>
    <!--/ Multi-view-video. -->
    <div class="container is-max-desktop">
      
      <div class="columns is-centered">
  
        <!-- Visual Effects. -->
        <div class="column">
          <video id="messi" autoplay controls muted loop playsinline>
              <source src="./static/videos/multi_view_video.mp4"
                      type="video/mp4">
          </video>
        </div>
        <!--/ Visual Effects. -->
  
      </div>
    </div>

     <!-- Multi-view-video. -->
     <div class="container is-max-desktop">

      <div class="columns is-centered">

        <!-- Visual Effects. -->
        <div class="column">
          <div class="content">
            <h2 class="title is-3">Ablation Study</h2>
            <!--<img src="./static/images/exhibit_mode23.jpg" alt="Video-to-4D">-->
          </div>
        </div>
        <!--/ Visual Effects. -->
  
        
        </div>
      </div>
    <!--/ Multi-view-video. -->
    <div class="container is-max-desktop">
      
      <div class="columns is-centered">
  
        <!-- Visual Effects. -->
        <div class="column">
          <video id="messi" autoplay controls muted loop playsinline>
              <source src="./static/videos/ablation.mp4"
                      type="video/mp4">
          </video>
        </div>
        <!--/ Visual Effects. -->
  
      </div>
    </div>

</section>






<section class="section" id="BibTeX">

    <div class="container is-max-desktop content">
  
    <h2 class="title">BibTeX</h2>
  
      <pre><code>@article{zhang20244diffusion,
    title={4Diffusion: Multi-view Video Diffusion Model for 4D Generation}, 
    author={Haiyu Zhang and Xinyuan Chen and Yaohui Wang and Xihui Liu and Yunhong Wang and Yu Qiao},
    year={2024}
}</code></pre>
  
   </div>
  
  </section>


<!--/TODO: insert citation. -->
<!--TODO: modeify bibtex-->



<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Thanks for Nerfie for release their project page code. We borrow their <a
              href="https://github.com/nerfies/nerfies.github.io">website code</a> to construct this website.
            
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
